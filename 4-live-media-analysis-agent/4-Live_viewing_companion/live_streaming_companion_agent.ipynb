{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Stream Companion Agent\n",
    "\n",
    "This module demonstrates how to build agent application leveraging the live vidoe analysis from previous modules: \n",
    "\n",
    "- Module 20 (Visual Understanding) for scene change detection with visual analysis\n",
    "- Module 30 (Audio Understanding) for speech-to-text transcription\n",
    "- Module 40 (Modality Fused Understanding) for chapter and topic boundary detection\n",
    "\n",
    "\n",
    "You will build this agent using [Strands Agents](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/model-providers/amazon-bedrock/) and [Amazon Bedrock AgentCore](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/what-is-bedrock-agentcore.html). It will processes live events from previous modules in real-time, serving as a viewing companion that provides instant context, generates ongoing summaries, and offers quick access to key moments—all designed to enhance viewer engagement and experience.\n",
    "\n",
    "<img src=\"images/architecture.png\" alt=\"Visual Understanding Architecture\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module incrementally builds the agent's capabilities toward a final cloud-deployed version. You will progress through the following steps:\n",
    "\n",
    "1. Introduction to Strands Agent\n",
    "2. Building live agent memory for video understanding\n",
    "3. Building agent tools for show summarization and key event search\n",
    "4. Deploying the agent to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from IPython.display import Markdown, display, HTML, JSON\n",
    "from contextlib import redirect_stdout\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "import json_repair\n",
    "\n",
    "\n",
    "%store -r AUDIOVISUAL_MODEL_ID\n",
    "%store -r AWS_REGION\n",
    "%store -r kb_id\n",
    "%store -r ds_id\n",
    "%store -r data_bucket_name\n",
    "%store -r chapter_mem_id\n",
    "%store -r chapter_session_id\n",
    "%store -r actor_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction to Strands Agents\n",
    "\n",
    "Strands Agent is an open-source SDK developed by AWS to help developers simplify agent development. At its core, Strands adopts a model-driven approach, allowing agents to leverage language models' natural capabilities. The agent building process is streamlined to just three components: a language model, a prompt that defines its behavior, and a set of tools it can use. \n",
    "\n",
    "Here is a quick example to illustrate and get you started on a simple agent that can answer questions about the current workshop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Tools\n",
    "@tool\n",
    "def get_session_name() -> str:\n",
    "    \"\"\"Get the title of the current workshop session\"\"\"\n",
    "    return \"Build Live Video Understanding fSolutions Using Ageentic AI On AWS (IND319)\"\n",
    "\n",
    "@tool \n",
    "def get_session_detail() -> str:\n",
    "    \"\"\"Get the session detail and key learning objectives\"\"\"\n",
    "    return \"\"\"\n",
    "    This workshop shows how to enhance live video processing using AI agents on AWS. Using Strands Agent SDK and Amazon Bedrock AgentCore, you'll learn to build intelligent systems that analyze live broadcast content in real-time, generate automated metadata, and enable improved content discovery. The hands-on exercises focus on implementing practical agent-driven solutions for media operations and content monetization.\n",
    "    \"\"\"\n",
    "\n",
    "@tool\n",
    "def get_session_location() -> str:\n",
    "    \"\"\"Get the location of the current workshop session\"\"\"\n",
    "    return \"Where: Mandalay Bay Ballroom K\"\n",
    "\n",
    "@tool\n",
    "def get_speakers() -> str:\n",
    "    \"\"\"Get the location of the current workshop session\"\"\"\n",
    "    return \"Speakers: Maheshwaran G, Principal Solution Architect and James Wu, Principle AI/ML Specialist SA\"\n",
    "\n",
    "# 1) Bedrock model\n",
    "bedrock_model = BedrockModel(\n",
    "  model_id=AUDIOVISUAL_MODEL_ID,\n",
    "  temperature=0.3,\n",
    "  streaming=True,\n",
    ")\n",
    "\n",
    "# 3) prompt\n",
    "system_prompt = \"\"\"You're a helpful workshop assistant. Answer questions about the current session.\n",
    "    Guideline: \n",
    "    1. answer user query in clear, concise, and polite manner.\n",
    "    3. never ask questions back to the user.\n",
    "    2. DO NOT answer query outside the context of this workshop session.\n",
    "    \"\"\"\n",
    "\n",
    "# Initialize Agent\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=system_prompt,\n",
    "    callback_handler=None,\n",
    "    tools=[get_session_name, get_session_location, get_speakers, get_session_detail]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some questions you can ask the agent:\n",
    "\n",
    "- Who are the speakers for this workshop?\n",
    "- What is the current location?\n",
    "- What is the name of this session?\n",
    "- What is this workshop all about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = agent(prompt=\"What is this workshop all about?\")\n",
    "\n",
    "# Parse result\n",
    "try:\n",
    "    response_text = result.get('output', result) if isinstance(result, dict) else str(result)\n",
    "    display(Markdown(response_text))\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    print(f\"Raw response: {str(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Building live agent memory for video understanding\n",
    "\n",
    "You saw how easy it is to build an agent using Strands. Now, you will tackle a more challenging problem: how can we enable our agent to understand live streaming video in real-time?\n",
    "\n",
    "While we could build a tool that queries live video events from our previous lab, we're going to take a more elegant approach using agent memory. This method allows our agent to maintain immediate awareness of streaming content with minimal latency.\n",
    "\n",
    "We'll leverage [Amazon Bedrock AgentCore Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory.html), a fully managed AWS service designed for maintaining both short-term and long-term context in AI agents. By integrating this memory system, we can continuously ingest live stream events, allowing our agent to maintain up-to-the-moment awareness of what's happening in the video stream.\n",
    "\n",
    "<img src=\"images/local_agent_memory.png\" alt=\"Visual Understanding Architecture\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Memory Parameters\n",
    "\n",
    "**chapter_memory_id:** Unique identifier for a memory store, referencing the specific memory instance being used.\n",
    "\n",
    "**actor_id:** Identifies the entity (in this case the user) that the memory belongs to, ensuring correct association with individuals or systems.\n",
    "\n",
    "**session_id:** Unique identifier for a particular conversation or interaction (in this case one viewing session on the streaming platform), grouping all related messages from that session.\n",
    "\n",
    "**namespaces:** Structured, hierarchical path used to logically group and organize memories, enabling separation by actor, session, strategy, or other criteria for clarity and access control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentcore_helper import create_memory_execution_role\n",
    "from datetime import datetime, timezone\n",
    "import random\n",
    "import string\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "memory_client = MemoryClient(region_name=AWS_REGION)\n",
    "agentcore_client = boto3.client('bedrock-agentcore', region_name=AWS_REGION)\n",
    "\n",
    "## create a dummy user_id and session_id representing a unique user and their viewing session\n",
    "rolling_summary_namespace = f\"summary/{actor_id}/{chapter_session_id}\"\n",
    "semantic_namespace = f\"semantic/{actor_id}\"\n",
    "\n",
    "print(f\"User: '{actor_id}', started a new viewing session: '{chapter_session_id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step memory hook\n",
    "\n",
    "There are multiple ways to attach memory to your Strands agent. You can use [AgentCoreMemorySessionManager](https://github.com/aws/bedrock-agentcore-sdk-python/blob/main/src/bedrock_agentcore/memory/integrations/strands/README.md), create a Memory Hook to insert context into the system prompt, or attach memory as a tool for the agent to use. We will show both Memory Hook and Memory as a tool in this module.\n",
    "\n",
    "Let's start with the memory hook. Strands Agents provide a hook feature, which is a callback mechanism that intercepts key agent lifecycle events (such as message addition or after tool invocation).\n",
    "\n",
    "With this feature, we can create a memory hook to manage and synchronize short-term during specific agent state to ensure the agent maintains correct context as new events are streaming in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.hooks import AgentInitializedEvent, HookProvider, HookRegistry, MessageAddedEvent\n",
    "\n",
    "class MemoryHook(HookProvider):\n",
    "    def __init__(self, agentcore_client, memory_id, actor_id, session_id):\n",
    "        self.agentcore_client = agentcore_client\n",
    "        self.memory_id = memory_id\n",
    "        self.actor_id = actor_id\n",
    "        self.session_id = session_id\n",
    "\n",
    "    def on_agent_initialized(self, event: AgentInitializedEvent):\n",
    "        \"\"\"Load recent events and metadata from short-term memory when agent starts\"\"\"\n",
    "        try:\n",
    "            # Get the most recent event with metadata\n",
    "            events_resp = self.agentcore_client.list_events(\n",
    "                memoryId=self.memory_id,\n",
    "                actorId=self.actor_id,\n",
    "                sessionId=self.session_id,\n",
    "                maxResults=1,\n",
    "                includePayloads=True\n",
    "            )\n",
    "            \n",
    "            if events_resp.get('events'):\n",
    "                latest_event = events_resp['events'][0]\n",
    "                \n",
    "                # Extract event content\n",
    "                events = []\n",
    "                for payload in latest_event.get('payload', []):\n",
    "                    if 'conversational' in payload:\n",
    "                        conv = payload['conversational']\n",
    "                        events.append(f\"{conv.get('role')}: {conv.get('content', {}).get('text', '')}\")\n",
    "                \n",
    "                # Extract metadata\n",
    "                metadata = latest_event.get('metadata', {})\n",
    "                metadata_info = []\n",
    "                if 'title' in metadata:\n",
    "                    metadata_info.append(f\"Show: {metadata['title'].get('stringValue', '')}\")\n",
    "                if 'genre' in metadata:\n",
    "                    metadata_info.append(f\"Genre: {metadata['genre'].get('stringValue', '')}\")\n",
    "                if 'start_ms' in metadata and 'end_ms' in metadata:\n",
    "                    start = metadata['start_ms'].get('stringValue', '0')\n",
    "                    end = metadata['end_ms'].get('stringValue', '0')\n",
    "                    metadata_info.append(f\"Timestamp: {start}ms - {end}ms\")\n",
    "                \n",
    "                # Build context with metadata\n",
    "                context_parts = []\n",
    "                if metadata_info:\n",
    "                    context_parts.append(\"Show Information:\\n\" + \"\\n\".join(metadata_info))\n",
    "                if events:\n",
    "                    context_parts.append(\"\\nMost Recent Event:\\n\" + \"\\n\".join(events))\n",
    "                \n",
    "                if context_parts:\n",
    "                    event.agent.system_prompt += \"\\n\\n\" + \"\\n\\n\".join(context_parts)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Memory load error: {e}\")\n",
    "    \n",
    "    def register_hooks(self, registry: HookRegistry):\n",
    "        registry.add_callback(AgentInitializedEvent, self.on_agent_initialized)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attached the Memory hook to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a companion agent watching a live streaming show with the viewer. you receive events when topic changes in the show.\n",
    "Guideline:\n",
    "\n",
    "- Only respond to the user question about the show\n",
    "- If provided, closely follow the output format user asked for. No extra explanations\n",
    "- Don't ask questions back\n",
    "- Respond in clear and professional manner\n",
    "- Summarize response in one complete paragraphs, long response need ot follow chronological order\n",
    "- DO NOT respond to questions outside of the shows you are watching.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=system_prompt,\n",
    "    callback_handler=None,\n",
    "    hooks=[MemoryHook(agentcore_client, chapter_mem_id, actor_id, chapter_session_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke agent and see what happens when our agent memory is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent(prompt=\"what are we currently watching?\")\n",
    "\n",
    "# Parse result\n",
    "try:\n",
    "    response_text = result.get('output', result) if isinstance(result, dict) else str(result)\n",
    "    display(Markdown(response_text))\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    print(f\"Raw response: {str(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the live stream events from the previous lab. We will load data every 5 seconds, simulating live stream video insights incrementally arriving in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "def sanitize_metadata_value(value: str) -> str:\n",
    "    r\"\"\"Sanitize metadata value to match pattern: [a-zA-Z0-9\\s._:/=+@-]*\"\"\"\n",
    "    # Replace parentheses and other invalid chars with spaces or remove them\n",
    "    value = value.replace('(', ' ').replace(')', ' ')\n",
    "    # Keep only allowed characters\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s._:/=+@-]', '', value).strip()\n",
    "\n",
    "\"\"\"Load topics into memory with metadata\"\"\"\n",
    "with open('chapters.jsonl', 'r') as f:\n",
    "    chapters = [json.loads(line) for line in f]\n",
    "\n",
    "chapters = chapters[:10]\n",
    "\n",
    "for i, chapter in enumerate(chapters[:10]):\n",
    "    # Prepare metadata (all values must be strings and match the pattern)\n",
    "    metadata = {\n",
    "        'title': {'stringValue': sanitize_metadata_value(chapter.get('show_title', ''))},\n",
    "        'genre': {'stringValue': sanitize_metadata_value(chapter.get('genre', ''))},\n",
    "        'start_ms': {'stringValue': str(chapter.get('start_ms', 0))},\n",
    "        'end_ms': {'stringValue': str(chapter.get('end_ms', 0))}\n",
    "    }\n",
    "    \n",
    "    # Build payload\n",
    "    payload = [\n",
    "        {'conversational': {'content': {'text': f\"Chapter {i}\"}, 'role': 'USER'}},\n",
    "        {'conversational': {'content': {'text': chapter['topic_summary']}, 'role': 'ASSISTANT'}}\n",
    "    ]\n",
    "    \n",
    "    # Use bedrock client directly to add metadata\n",
    "    agentcore_client.create_event(\n",
    "        memoryId=chapter_mem_id,\n",
    "        actorId=actor_id,\n",
    "        sessionId=chapter_session_id,\n",
    "        eventTimestamp=datetime.now(timezone.utc),\n",
    "        payload=payload,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    \n",
    "    # Rate limit: 0.25 TPS per actor/session = 1 request every 4 seconds\n",
    "    print(f\"  Loaded chapter {i+1} ({i+1}/{len(chapters)}) - {chapter.get('start_ms', 0)}ms to {chapter.get('end_ms', 0)}ms\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the livestream is happening and we are currently playing Chapter 10, watch this part of the video. Play a few seconds to verify if the agent has the correct content of what's currently playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_video_segment(video_path, start_time, end_time=10000, width=640, height=360):\n",
    "    randint = random.randint(0, 100000)\n",
    "    html = f\"\"\"\n",
    "    <video id=\"myvideo-{randint}\" width=\"{width}\" height=\"{height}\" controls>\n",
    "        <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    <script>\n",
    "    (function() {{\n",
    "        const video = document.getElementById(\"myvideo-{randint}\");\n",
    "        \n",
    "        // Wait for metadata to load\n",
    "        video.addEventListener('loadedmetadata', function() {{\n",
    "            video.currentTime = {start_time};\n",
    "        }});\n",
    "        \n",
    "        // Fallback: also try on canplay event\n",
    "        video.addEventListener('canplay', function() {{\n",
    "            if (video.currentTime === 0) {{\n",
    "                video.currentTime = {start_time};\n",
    "            }}\n",
    "        }});\n",
    "        \n",
    "        // Add timeupdate listener to check for end time\n",
    "        video.addEventListener('timeupdate', function() {{\n",
    "            if (video.currentTime >= {end_time}) {{\n",
    "                video.pause();\n",
    "                video.currentTime = {end_time};\n",
    "            }}\n",
    "        }});\n",
    "        \n",
    "        // Force load\n",
    "        video.load();\n",
    "    }})();\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    return HTML(html)\n",
    "\n",
    "# Usage\n",
    "video_path = '../sample_videos/Netflix_Open_Content_Meridian.mp4'\n",
    "current = chapters[len(chapters)-1]\n",
    "start_time = current['start_ms'] / 1000\n",
    "end_time = current['end_ms'] / 1000\n",
    "render_video_segment(video_path, start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the events are ingested, our agent has immediate context of what's happening.\n",
    "\n",
    "Here are some example queries you can try:\n",
    "\n",
    "What genre is this show?\n",
    "What show am I watching?\n",
    "What is happening right now?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=system_prompt,\n",
    "    callback_handler=None,\n",
    "    hooks=[MemoryHook(agentcore_client, chapter_mem_id, actor_id, chapter_session_id)],\n",
    ")\n",
    "\n",
    "result = agent(prompt=\"what show am I watching?\")\n",
    "\n",
    "# Parse result\n",
    "try:\n",
    "    response_text = result.get('output', result) if isinstance(result, dict) else str(result)\n",
    "    display(Markdown(response_text))\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    print(f\"Raw response: {str(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Building agent tools for show summarization and key event search\n",
    "\n",
    "Now we are going to add some tools to improve our agent to support couple new use cases. Using the `@tool` decorator in Strands makes it extremely easy to build tools by simply annotating regular Python functions, which automatically converts them into agent-callable tools with metadata and input validation generated from the function’s docstring and type hints.\n",
    "\n",
    "We are going to add 2 tools:\n",
    "\n",
    "1. summarize show up to now\n",
    "2. find key moments\n",
    "\n",
    "<img src=\"images/local_agent_tools.png\" alt=\"Visual Understanding Architecture\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long-term memory strategy\n",
    "\n",
    "Here we want to introduce the concept of long-term memory strategy in AgentCore Memory. Unlike short-term memory that just stores transactional memory data, long-term memory strategy determines how interactions are extracted, structured, and stored persistently across sessions, turning insights into vector-searchable knowledge.\n",
    "\n",
    "Built-in strategies include semantic memory (facts), user preference memory, and session summary memory. Custom memory strategies allow full control over extraction and consolidation logic by defining your own algorithms, prompts, models, and data schemas. You can have multiple memory strategies attached to a memory store focusing on different purposes, and they are logically separated by namespaces.\n",
    "\n",
    "In this example, we have pre-generated a long-term memory that is asynchronously extracting rolling summaries of the show. Below is how that memory was defined in Python.\n",
    "\n",
    "``` python\n",
    "custom_strategy = {\n",
    "    \"customMemoryStrategy\": {\n",
    "        \"name\": \"rolling_summary\",\n",
    "        \"namespaces\": [\"summary/{actorId}/{sessionId}\"],\n",
    "        \"configuration\": {\n",
    "            \"summaryOverride\": {\n",
    "                \"consolidation\": {\n",
    "                    \"appendToPrompt\": \"Merge new info with existing summary. Keep previous info and add new. This is cumulative - grow, don't replace.\",\n",
    "                    \"modelId\": AUDIOVISUAL_MODEL_ID\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_show_summary():\n",
    "    \"\"\"\n",
    "    Retrieve a comprehensive summary of what has happened in the current live video show so far.\n",
    "    Combines rolling summary information with the latest events from the video understanding system.\n",
    "    Use this when users ask about show content, current topics, or what they've missed.\n",
    "    \n",
    "    Returns:\n",
    "        String containing the show summary and latest updates, or error message if unavailable\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get latest summary from memory records\n",
    "        summary_resp = agentcore_client.list_memory_records(\n",
    "            memoryId=chapter_mem_id,\n",
    "            namespace=rolling_summary_namespace,\n",
    "            maxResults=1\n",
    "        )\n",
    "        summary = summary_resp['memoryRecordSummaries'][0]['content']['text'] if summary_resp['memoryRecordSummaries'] else \"\"\n",
    "        \n",
    "        # Get latest event\n",
    "        events_resp = agentcore_client.list_events(\n",
    "            memoryId=chapter_mem_id,\n",
    "            actorId=actor_id,\n",
    "            sessionId=chapter_session_id,\n",
    "            maxResults=1,\n",
    "            includePayloads=True\n",
    "        )\n",
    "        \n",
    "        latest_event = \"\"\n",
    "        if events_resp.get('events'):\n",
    "            for payload in events_resp['events'][0].get('payload', []):\n",
    "                if 'conversational' in payload:\n",
    "                    latest_event = payload['conversational']['content']['text']\n",
    "        \n",
    "        # Combine summary and latest event\n",
    "        context = []\n",
    "        if summary:\n",
    "            context.append(f\"Show Summary: {summary}\")\n",
    "        if latest_event:\n",
    "            context.append(f\"Latest Update: {latest_event}\")\n",
    "            \n",
    "        return \"\\n\\n\".join(context) if context else \"No show information available yet.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Unable to retrieve show summary: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maker Sure Long Term Strategy Extraction is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = 180\n",
    "start = time.time()\n",
    "while time.time() - start < timeout:\n",
    "    try:\n",
    "        response = agentcore_client.list_memory_records(\n",
    "            memoryId=chapter_mem_id,\n",
    "            namespace=rolling_summary_namespace,\n",
    "            maxResults=1\n",
    "        )\n",
    "        if response['memoryRecordSummaries']:\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the `get_show_summary` tool to our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=[get_show_summary],\n",
    "    hooks=[MemoryHook(agentcore_client, chapter_mem_id, actor_id, chapter_session_id)],\n",
    ")\n",
    "\n",
    "result = agent(prompt=\"can you give me a summary of the show so far?\")\n",
    "\n",
    "# Parse result\n",
    "try:\n",
    "    response_text = result.get('output', result) if isinstance(result, dict) else str(result)\n",
    "    display(Markdown(response_text))\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    print(f\"Raw response: {str(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Key Event Search\n",
    "\n",
    "At the same time, we will ingest the events to Bedrock Knowledge Base for key moment search\n",
    "\n",
    "create a few helper function to help us upload the events to S3 and dynamically ingest them into Bedrock knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_config = Config(\n",
    "    connect_timeout=120,\n",
    "    read_timeout=120,\n",
    "    retries={'max_attempts': 0},\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "# Initialize clients\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent', config=bedrock_config)\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=AWS_REGION)\n",
    "\n",
    "def upload_chapter_to_s3(s3_client, bucket_name, chapter, idx):\n",
    "    \"\"\"\n",
    "    Upload chapter content to S3 and return the S3 URI.\n",
    "    \n",
    "    Args:\n",
    "        s3_client: Boto3 S3 client\n",
    "        bucket_name: S3 bucket name\n",
    "        chapter: Chapter dictionary with metadata\n",
    "        idx: Chapter index\n",
    "        \n",
    "    Returns:\n",
    "        S3 URI of the uploaded file\n",
    "    \"\"\"\n",
    "    start_sec = chapter['start_ms'] // 1000\n",
    "    end_sec = chapter['end_ms'] // 1000\n",
    "    filename = f\"chapters/chapter_{idx:03d}_{start_sec}_{end_sec}.txt\"\n",
    "    \n",
    "    content = chapter[\"topic_summary\"]\n",
    "    \n",
    "    s3_client.put_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=filename,\n",
    "        Body=content.encode('utf-8'),\n",
    "        ContentType='text/plain'\n",
    "    )\n",
    "    \n",
    "    return f\"s3://{bucket_name}/{filename}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Document Level API (DLA), customers can now efficiently and cost-effectively ingest, update, or delete data directly from Amazon Bedrock Knowledge Bases using a single API call, without the need to perform a full sync with the data source periodically or after every change.\n",
    "\n",
    "To read more about DLA, see the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/kb-direct-ingestion-add.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "for idx, chapter in enumerate(chapters):\n",
    "    try:\n",
    "        # Upload to S3 and get URI\n",
    "        s3_uri = upload_chapter_to_s3(s3_client, data_bucket_name, chapter, idx)\n",
    "        \n",
    "        # Prepare metadata\n",
    "        start_sec = chapter['start_ms'] // 1000\n",
    "        end_sec = chapter['end_ms'] // 1000\n",
    "        metadata_attributes = [\n",
    "            {'key': 'show_title', 'value': {'stringValue': chapter['show_title'], 'type': 'STRING'}},\n",
    "            {'key': 'genre', 'value': {'stringValue': chapter['genre'], 'type': 'STRING'}},\n",
    "            {'key': 'start_ms', 'value': {'numberValue': chapter['start_ms'], 'type': 'NUMBER'}},\n",
    "            {'key': 'end_ms', 'value': {'numberValue': chapter['end_ms'], 'type': 'NUMBER'}},\n",
    "        ]\n",
    "        \n",
    "        # Ingest to Knowledge Base\n",
    "        document_config = {\n",
    "            'content': {\n",
    "                'dataSourceType': 'CUSTOM',\n",
    "                'custom': {\n",
    "                    'customDocumentIdentifier': {'id': f\"chapter_{idx:03d}\"},\n",
    "                    'sourceType': 'S3_LOCATION',\n",
    "                    's3Location': {'uri': s3_uri}\n",
    "                }\n",
    "            },\n",
    "            'metadata': {\n",
    "                'type': 'IN_LINE_ATTRIBUTE',\n",
    "                'inlineAttributes': metadata_attributes\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        bedrock_agent_client.ingest_knowledge_base_documents(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            dataSourceId=ds_id,\n",
    "            documents=[document_config]\n",
    "        )\n",
    "        \n",
    "        successful += 1\n",
    "        if (idx + 1) % 5 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(chapters)}\")\n",
    "            time.sleep(1)\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        print(f\"Failed chapter {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "@tool\n",
    "def search_key_moments(query: str, max_results: int = 2) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search key moments of the video from Knowledge Base.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query text describing what you're looking for\n",
    "        max_results: Maximum number of results to return (default: 2)\n",
    "        \n",
    "    Returns:\n",
    "        List of chapters with content, start_ms, and end_ms\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    response = bedrock_agent_runtime.retrieve(\n",
    "        knowledgeBaseId=kb_id,\n",
    "        retrievalQuery={'text': query},\n",
    "        retrievalConfiguration={\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': max_results\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for result in response['retrievalResults']:\n",
    "        metadata = result.get('metadata', {})\n",
    "        results.append({\n",
    "            'content': result['content']['text'],\n",
    "            'start_ms': metadata.get('start_ms', 0),\n",
    "            'end_ms': metadata.get('end_ms', 0)\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to help us parse the reponse into valide dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_from_text(text: str) -> list:\n",
    "    \"\"\"Parse JSON and convert string numbers to integers.\"\"\"\n",
    "    text = re.sub(r'```json\\s*', '', text)\n",
    "    text = re.sub(r'```\\s*$', '', text)\n",
    "    text = text.replace('\\\\\"', '\"')\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "    text = text.replace('\\\\:', ':')\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = text.replace(\" _ms\", \"_ms\") #fix spaces\n",
    "\n",
    "    data =  json_repair.loads(text)\n",
    "    print(data)\n",
    "    \n",
    "    # Convert string numbers to integers\n",
    "    for item in data:\n",
    "        if 'start_ms' in item:\n",
    "            item['start_ms'] = float(item['start_ms'])\n",
    "        if 'end_ms' in item:\n",
    "            item['end_ms'] = float(item['end_ms'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "I want to find a moment where vintage car driving in the winding road\n",
    "\n",
    "output list of JSON object only, strickly follow the schema below. Every JSON object MUST HAVE attributes: \"content\", \"start_ms\", \"end_ms\"\n",
    "[\n",
    "    {\"content\": \"...\", \"start_ms\": \"...\", \"end_ms\": \"...\"},\n",
    "    {\"content\": \"...\", \"start_ms\": \"...\", \"end_ms\": \"...\"},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=[get_show_summary, search_key_moments],\n",
    "    hooks=[MemoryHook(agentcore_client, chapter_mem_id, actor_id, chapter_session_id)],\n",
    ")\n",
    "\n",
    "result = agent(prompt=prompt)\n",
    "\n",
    "# Parse result\n",
    "try:\n",
    "    response_text = result.get('output', result) if isinstance(result, dict) else str(result)\n",
    "\n",
    "    results = parse_json_from_text(response_text)\n",
    "\n",
    "    for r in results:\n",
    "        display(Markdown(f\"Chapter summary: {r['content']}\"))\n",
    "        start = r['start_ms']/1000\n",
    "        end = r['end_ms']/1000\n",
    "        display(render_video_segment(video_path, start, end))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    print(f\"Raw response: {str(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 4. Deploying the agent to production\n",
    "\n",
    "<img src=\"images/agentcore_runtime.png\" alt=\"Visual Understanding Architecture\" width=\"800\">\n",
    "\n",
    "Now we will deploy the agent to Amazon Bedrock AgentCore runtime. before that, we need to store all configuration parameters in AWS Systems Manager Parameter Store so the runtime can access them.\n",
    "\n",
    "**Why SSM Parameter Store?**\n",
    "- The AgentCore Runtime needs configuration to connect to memory\n",
    "- SSM provides secure, centralized configuration management\n",
    "- The runtime's IAM role will have permission to read these parameters\n",
    "- Easy to update configuration without redeploying the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store configuration parameters in SSM for runtime access\n",
    "ssm_client = boto3.client('ssm', region_name=AWS_REGION)\n",
    "\n",
    "# Define all parameters to store\n",
    "parameters = {\n",
    "    '/viewing-companion/model_id': AUDIOVISUAL_MODEL_ID,\n",
    "    '/viewing-companion/memory_id': chapter_mem_id,\n",
    "    '/viewing-companion/actor_id': actor_id,\n",
    "    '/viewing-companion/session_id': chapter_session_id,\n",
    "    '/viewing-companion/rolling_summary_namespace': rolling_summary_namespace,\n",
    "    '/viewing-companion/kb_id': kb_id\n",
    "}\n",
    "\n",
    "print(\"Storing configuration in SSM Parameter Store...\\n\")\n",
    "\n",
    "for param_name, param_value in parameters.items():\n",
    "    ssm_client.put_parameter(\n",
    "        Name=param_name,\n",
    "        Value=param_value,\n",
    "        Type='String',\n",
    "        Overwrite=True\n",
    "    )\n",
    "    print(f\"✓ Stored: {param_name}\")\n",
    "    print(f\"  Value: {param_value}\")\n",
    "\n",
    "print(\"\\n✅ All configuration stored in SSM Parameter Store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll combine the code into a clean script. To ensure compatibility with AgentCore runtime, you need to make the following changes to your script:\n",
    "\n",
    "- Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "- Initialize the App in your code with `app = BedrockAgentCoreApp()`\n",
    "- Decorate the invocation function with the `@app.entrypoint decorator`\n",
    "- Let AgentCoreRuntime control the running of the agent with `app.run()`\n",
    "\n",
    "This setup remains the same regardless of which agent framework you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"script/viewing_companion_agent.py\", \"r\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "display(Markdown(f\"\"\"```python\n",
    "{code}\n",
    "```\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure AgentCore Runtime\n",
    "\n",
    "Configure the runtime deployment with execution permissions.\n",
    "\n",
    "**Configuration Parameters:**\n",
    "\n",
    "1. **Entrypoint** - `script/viewing_companion_agent.py`\n",
    "   - Python file with `BedrockAgentCoreApp` and `@app.entrypoint`\n",
    "   - Entry point for request handling\n",
    "\n",
    "2. **Execution Role** - IAM role for runtime permissions\n",
    "   - Grants access to SSM Parameter Store\n",
    "   - Allows CloudWatch Logs writing\n",
    "   - Enables Bedrock model invocation\n",
    "   - Allows AgentCore Memory access\n",
    "\n",
    "3. **Auto-create ECR** - Automatically creates ECR repository\n",
    "   - Stores Docker container images\n",
    "   - Manages image versioning\n",
    "\n",
    "4. **Requirements File** - `script/requirements.txt`\n",
    "   - Lists Python dependencies\n",
    "   - Installed during container build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper\n",
    "from agentcore_helper import AgentCoreHelper\n",
    "\n",
    "# Initialize helper\n",
    "agentcore_helper = AgentCoreHelper(region_name=AWS_REGION)\n",
    "\n",
    "# Agent configuration\n",
    "agent_name = \"live_streaming_companion_agent\"\n",
    "execution_role_name = f\"{agent_name}_role\"\n",
    "execution_policy_name = f\"{agent_name}_policy\"\n",
    "\n",
    "print(f\"Agent name: {agent_name}\")\n",
    "print(f\"Execution role: {execution_role_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove left over configuration scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf .bedrock_agentcore.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "\n",
    "# Create execution role with necessary permissions\n",
    "execution_role_arn = agentcore_helper.create_agentcore_runtime_execution_role(\n",
    "    role_name=execution_role_name,\n",
    "    policy_name=execution_policy_name\n",
    ")\n",
    "\n",
    "print(f\"✓ Execution role created: {execution_role_arn}\")\n",
    "time.sleep(40) # add wait for role policy to propogate\n",
    "\n",
    "# Initialize runtime toolkit\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "# Configure the deployment\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"script/viewing_companion_agent.py\",\n",
    "    execution_role=execution_role_arn,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"script/requirements.txt\",\n",
    "    region=AWS_REGION,\n",
    "    agent_name=agent_name,\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Runtime configuration completed\")\n",
    "print(f\"Agent name: {agent_name}\")\n",
    "print(f\"Entrypoint: script/viewing_companion_agent.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Runtime\n",
    "\n",
    "Deploy the agent to AgentCore Runtime. This will:\n",
    "1. Build a Docker container with your agent code\n",
    "2. Push the container to Amazon ECR\n",
    "3. Create an AgentCore Runtime with the container\n",
    "4. Configure auto-scaling and monitoring\n",
    "\n",
    "**Note:** This step takes 5-10 minutes as it builds and deploys the container.\n",
    "\n",
    "If the agent already exists, use `auto_update_on_conflict=True` to update it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the runtime (builds and deploys the container)\n",
    "print(\"Launching runtime... This may take 5-10 minutes.\\n\")\n",
    "\n",
    "launch_result = agentcore_runtime.launch(\n",
    "    auto_update_on_conflict=True  # Update if agent already exists\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Runtime launched successfully!\")\n",
    "print(f\"Agent ARN: {launch_result.agent_arn}\")\n",
    "print(f\"Agent ID: {launch_result.agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for Deployment\n",
    "\n",
    "Monitor the runtime deployment until it's ready to accept requests.\n",
    "\n",
    "**Runtime States:**\n",
    "- `CREATING` - Container is being deployed\n",
    "- `UPDATING` - Runtime is being updated\n",
    "- `READY` - Runtime is ready to accept requests\n",
    "- `CREATE_FAILED` - Deployment failed\n",
    "- `UPDATE_FAILED` - Update failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the agent to be ready\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint[\"status\"]\n",
    "\n",
    "end_status = [\"READY\", \"CREATE_FAILED\", \"DELETE_FAILED\", \"UPDATE_FAILED\"]\n",
    "while status not in end_status:\n",
    "    print(f\"Waiting for deployment... Current status: {status}\")\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint[\"status\"]\n",
    "\n",
    "if status == 'READY':\n",
    "    print(f\"Runtime is ready! Status: {status}\")\n",
    "else:\n",
    "    print(f\"Final status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Deployed Agent\n",
    "\n",
    "Let's try the same use cases to test our agent now running in Bedrock AgentCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_arn = launch_result.agent_arn\n",
    "\n",
    "print(f\"Ready to invoke agent: {agent_arn}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use case 1: What I am currently watching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"prompt\":\"What show am I watching?\"}\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# Handle streaming response (SSE format)\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    print(\"Processing streaming response...\")\n",
    "    content = []\n",
    "    for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        if line:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data: \"):\n",
    "                data = line[6:].replace('\"', '')\n",
    "                content.append(data)\n",
    "    \n",
    "    full_response = \" \".join(content)\n",
    "    display(Markdown(full_response))\n",
    "else:\n",
    "    print(\"Non-streaming response received\")\n",
    "    print(boto3_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use case 2: summarize live show up to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"prompt\":\"can you give me a summary of the show so far?\"}\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# Handle streaming response (SSE format)\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    print(\"Processing streaming response...\")\n",
    "    content = []\n",
    "    for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        if line:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data: \"):\n",
    "                data = line[6:].replace('\"', '')\n",
    "                content.append(data)\n",
    "    \n",
    "    full_response = \" \".join(content)\n",
    "    display(Markdown(full_response))\n",
    "else:\n",
    "    print(\"Non-streaming response received\")\n",
    "    print(boto3_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use case 3: search for key moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"prompt\":\"\"\"\n",
    "\n",
    "I want to find a moment where vintage car driving in the winding road\n",
    "\n",
    "output list of JSON object only, strickly follow the schema below. Every JSON object MUST HAVE attributes: \"content\", \"start_ms\", \"end_ms\"\n",
    "[\n",
    "    {\"content\": \"...\", \"start_ms\": \"...\", \"end_ms\": \"...\"},\n",
    "    {\"content\": \"...\", \"start_ms\": \"...\", \"end_ms\": \"...\"},\n",
    "    ...\n",
    "]\n",
    "\"\"\"}\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# Handle streaming response (SSE format)\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    print(\"Processing streaming response...\")\n",
    "    content = []\n",
    "    for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        if line:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data: \"):\n",
    "                data = line[6:].replace('\"', '')\n",
    "                content.append(data)\n",
    "    \n",
    "    full_response = \" \".join(content)\n",
    "    display(Markdown(full_response))\n",
    "else:\n",
    "    print(\"Non-streaming response received\")\n",
    "    print(boto3_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse result\n",
    "try:\n",
    "    results = parse_json_from_text(full_response)\n",
    "\n",
    "    for r in results:\n",
    "        display(Markdown(f\"Chapter summary: {r['content']}\"))\n",
    "        start = r['start_ms']/1000\n",
    "        end = r['end_ms']/1000\n",
    "\n",
    "        display(render_video_segment(video_path, start, end))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    print(f\"Raw response: {str(full_response)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory_client.delete_memory_and_wait(\n",
    "#     memory_id=memory_id,\n",
    "#     max_wait=300,\n",
    "#     poll_interval=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete SSM parameters\n",
    "# ssm_parameters = [\n",
    "#     '/viewing-companion/model_id',\n",
    "#     '/viewing-companion/memory_id',\n",
    "#     '/viewing-companion/actor_id',\n",
    "#     '/viewing-companion/session_id',\n",
    "#     '/viewing-companion/rolling_summary_namespace',\n",
    "#     '/viewing-companion/kb_id'\n",
    "# ]\n",
    "\n",
    "# print(\"\\nDeleting SSM parameters...\")\n",
    "# for param in ssm_parameters:\n",
    "#     try:\n",
    "#         ssm_client.delete_parameter(Name=param)\n",
    "#         print(f\"✓ Deleted: {param}\")\n",
    "#     except ssm_client.exceptions.ParameterNotFound:\n",
    "#         print(f\"  (already deleted: {param})\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  Note: {e}\")\n",
    "\n",
    "# print(\"\\n✅ All SSM parameters deleted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete AgentCore Runtime\n",
    "# agentcore_helper.runtime_resource_cleanup(runtime_arn=launch_result.agent_arn)\n",
    "# print(\"✅ AgentCore Runtime deleted\")\n",
    "\n",
    "# # Delete IAM role and policy\n",
    "# agentcore_helper.delete_agentcore_runtime_execution_role(\n",
    "#     role_name=execution_role_name,\n",
    "#     policy_name=execution_policy_name\n",
    "# )\n",
    "# print(\"✅ IAM role and policy deleted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
