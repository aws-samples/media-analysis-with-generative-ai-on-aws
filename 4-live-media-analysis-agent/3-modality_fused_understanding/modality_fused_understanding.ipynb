{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modality Fused Understanding\n",
    "## Overview\n",
    "\n",
    "This notebook implements the **third and final layer of live video understanding** by combining visual and audio insights using Amazon Bedrock with Anthropic Claude for comprehensive multi-modal content understanding.\n",
    "\n",
    "The multi-modal fused understanding layer combines visual filmstrips and audio transcripts to detect topic boundaries, identify chapters, and create comprehensive content understanding. This fusion creates a complete picture of what's happening in your live broadcasts by analyzing both what's seen and what's heard together.\n",
    "\n",
    "**This module leverages the components developed in the Visual Understanding and Audio Understanding modules for continuous processing of the live stream**, integrating their capabilities into a unified multi-modal analysis pipeline.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "![Multi-modal Fused Understanding Architecture](images/acr_visual-audio-understanding.png)\n",
    "\n",
    "The architecture shows how visual filmstrips and audio transcripts are synchronized and analyzed together using Amazon Bedrock with Anthropic Claude to create comprehensive multi-modal understanding, which is then pushed to AgentCore Memory for downstream agentic AI applications.\n",
    "\n",
    "\n",
    "## Key Technologies Used\n",
    "\n",
    "- **Amazon Bedrock with Anthropic Claude Sonnet 4**: Multi-modal fusion and comprehensive content understanding\n",
    "- **Amazon Transcribe**: Real-time audio transcription with precise timestamps\n",
    "- **OpenCV**: Video processing and filmstrip generation\n",
    "- **FFmpeg**: Multi-stream video and audio ingestion\n",
    "- **Prompt Caching**: Cost optimization for repeated analysis and providing better performance\n",
    "- **Rolling Context Window**: Intelligent context management that maintains only recent chapters (n-1) to optimize latency and cost while preserving accuracy\n",
    "\n",
    "**üìù System Prompt**: The multi-modal analysis is powered by a comprehensive system prompt that guides Claude's understanding of video content. You can review the complete prompt at: [`prompts/video_analysis_system_prompt.txt`](prompts/video_analysis_system_prompt.txt)\n",
    "\n",
    "## Cost & Latency Optimization Techniques\n",
    "\n",
    "This notebook implements two powerful optimization techniques that dramatically reduce costs and improve performance:\n",
    "\n",
    "### 1. Prompt Caching - Dual Cache Breakpoint Strategy\n",
    "\n",
    "**Prompt Caching** implements a **dual cache breakpoint strategy** that partitions content into two distinct memory regions:\n",
    "\n",
    "- **Static Memory (First Breakpoint)**: Stores system prompts and instructions that remain constant across all API calls. This content is cached once and reused indefinitely, eliminating redundant token costs.\n",
    "\n",
    "- **Growing Memory (Second Breakpoint)**: Contains the incremental conversation between user and agent, including  transcripts and analysis results. The cache breakpoint moves forward with each new interaction, allowing the growing context to be cached while only paying for the new incremental content.\n",
    "\n",
    "This dual breakpoint approach enables up to 60% cost reduction on cached content while maintaining full conversational context. The static memory never changes, and the growing memory expands incrementally, with each new chunk only paying for the delta rather than reprocessing the entire history.\n",
    "\n",
    "### 2. Smart Context Windowing\n",
    "\n",
    "**Smart Context Windowing** employs chapter-based pruning that maintains recent context (n-1 chapters) while preventing context overflow. This novel approach to memory management enables unlimited video length processing with bounded memory, ensuring quality is maintained while optimizing both cost and latency.\n",
    "\n",
    "## Real-time Integration with AgentCore Memory\n",
    "\n",
    "As the notebook processes live video and creates comprehensive multi-modal understanding, the fused insights are automatically pushed to **Amazon Bedrock AgentCore Memory** in real-time. This enables downstream agentic AI applications that can query and use for intelligent decision-making, creating business value from the three-layer understanding you've built.\n",
    "\n",
    "**Let's see how this works in practice!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "**Load required modules** for multi-modal fusion processing, real-time streaming, and AI analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import queue\n",
    "import threading\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import boto3\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Audio processing imports\n",
    "from amazon_transcribe.client import TranscribeStreamingClient\n",
    "from amazon_transcribe.handlers import TranscriptResultStreamHandler\n",
    "from amazon_transcribe.model import TranscriptEvent\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Setup\n",
    "\n",
    "**Load shared configuration** from prerequisites notebook and set up processing parameters.\n",
    "\n",
    "### Configuration Components\n",
    "\n",
    "- **Model Settings** - Claude model ID and AWS region\n",
    "- **Memory Integration** - AgentCore Memory IDs for real-time storage\n",
    "- **Output Organization** - structured folders for recordings and analysis\n",
    "- **Processing Parameters** - chunk duration, FPS, and streaming ports\n",
    "- **Optimization Settings** - prompt caching and context windowing\n",
    "\n",
    "This ensures all fusion components work together seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load shared configuration from prerequisites notebook\n",
    "%store -r AUDIOVISUAL_MODEL_ID\n",
    "%store -r AWS_REGION\n",
    "\n",
    "# Use defaults if not set\n",
    "if 'AUDIOVISUAL_MODEL_ID' not in globals():\n",
    "    AUDIOVISUAL_MODEL_ID = \"global.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "    print(\"‚ö†Ô∏è  Using default AUDIOVISUAL_MODEL_ID (run prerequisites notebook to configure)\")\n",
    "\n",
    "if 'AWS_REGION' not in globals():\n",
    "    AWS_REGION = 'us-east-1'\n",
    "    print(\"‚ö†Ô∏è  Using default AWS_REGION (run prerequisites notebook to configure)\")\n",
    "else:\n",
    "    print(f\"‚úÖ Loaded Audiovisual Model ID: {AUDIOVISUAL_MODEL_ID}\")\n",
    "    print(f\"‚úÖ Loaded AWS Region: {AWS_REGION}\")\n",
    "\n",
    "# Configuration\n",
    "SOURCE_VIDEO = \"Netflix_Open_Content_Meridian.mp4\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "CHUNK_DURATION = 20  # seconds\n",
    "SOURCE_FPS = 30\n",
    "\n",
    "# UDP Ports for three streams\n",
    "UDP_PORT_RECORDING = \"1234\"    # Stream 1: Recording\n",
    "UDP_PORT_PROCESSING = \"1235\"   # Stream 2: Video processing\n",
    "UDP_PORT_TRANSCRIPTION = \"1236\" # Stream 3: Transcription\n",
    "\n",
    "TRANSCRIBE_LANGUAGE_CODE = 'en-US'\n",
    "TRANSCRIBE_SAMPLE_RATE = 16000\n",
    "\n",
    "# Global buffers\n",
    "SENTENCE_JSON_BUFFER = []\n",
    "CHUNK_ANALYSIS_RESULTS = {}\n",
    "FUSION_RESULTS = []\n",
    "\n",
    "# Directory cleanup will be handled by cleanup utilities in next cell\n",
    "# Create output directories structure\n",
    "output_subdirs = {\n",
    "    \"chunks\": f\"{OUTPUT_DIR}/chunks\",\n",
    "    \"filmstrips\": f\"{OUTPUT_DIR}/filmstrips\", \n",
    "    \"transcripts\": f\"{OUTPUT_DIR}/transcripts\",\n",
    "    \"analysis\": f\"{OUTPUT_DIR}/analysis\",\n",
    "    \"recording\": f\"{OUTPUT_DIR}/recording\",\n",
    "    \"clips\": f\"{OUTPUT_DIR}/clips\"\n",
    "}\n",
    "\n",
    "print(\"üöÄ Configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Components\n",
    "\n",
    "**Load processing components** for multi-modal fusion pipeline.\n",
    "\n",
    "**Shared Components** (reusable across modules):\n",
    "- **RecordingManager**: Handles continuous video recording to MXF format\n",
    "- **TranscriptionProcessor**: Manages real-time audio transcription via Amazon Transcribe\n",
    "- **TranscriptionHandler**: Processes transcription results and detects sentence boundaries\n",
    "- **ComponentMonitor**: Provides organized logging and activity tracking\n",
    "- **FilmstripProcessor**: Creates enhanced filmstrip grids with shot detection\n",
    "\n",
    "**Module-Specific Components** (Modality Fusion):\n",
    "- **ChunkProcessor**: Creates 20-second video chunks and triggers filmstrip creation\n",
    "- **FusionAnalyzer**: Performs multi-modal analysis using Amazon Bedrock with Anthropic Claude\n",
    "- **StreamMonitor**: Monitors component activity and detects stream end\n",
    "\n",
    "**AgentCore Memory**: Enables real-time knowledge storage for downstream agentic AI\n",
    "\n",
    "These components work together to create comprehensive multi-modal understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add project root to Python path to enable imports\n",
    "import sys\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "# Get project root (parent of current directory)\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"‚úÖ Added project root to Python path: {project_root}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Project root already in Python path: {project_root}\")\n",
    "\n",
    "# Import shared components (reusable across modules)\n",
    "from src.shared import (\n",
    "    RecordingManager,\n",
    "    TranscriptionProcessor,\n",
    "    TranscriptionHandler,\n",
    "    ComponentMonitor,\n",
    "    log_component,\n",
    "    set_debug_logging,\n",
    "    show_component_table,\n",
    "    FilmstripProcessor,\n",
    "    create_fusion_detector\n",
    ")\n",
    "\n",
    "# Import module-specific components (Modality Fusion)\n",
    "from components import (\n",
    "    ChunkProcessor,\n",
    "    ChunkMonitor,\n",
    "    FusionAnalyzer,\n",
    "    StreamMonitor,\n",
    "    CleanupUtils,\n",
    "    cleanup_directory,\n",
    "    cleanup_ffmpeg_processes,\n",
    "    cleanup_all,\n",
    "    ProcessingUtils,\n",
    "    start_fusion_processing\n",
    ")\n",
    "\n",
    "# Initialize component monitor\n",
    "component_monitor = ComponentMonitor()\n",
    "\n",
    "memory_client = boto3.client('bedrock-agentcore')\n",
    "\n",
    "# Load memory configuration from prerequisites notebook\n",
    "%store -r video_analysis_mem_id\n",
    "%store -r video_analysis_session_id\n",
    "%store -r transcript_mem_id\n",
    "%store -r trans_session_id\n",
    "%store -r actor_id\n",
    "\n",
    "# Clean up directories using utility class\n",
    "cleanup_directory(OUTPUT_DIR, output_subdirs)\n",
    "\n",
    "# Apply the setting\n",
    "set_debug_logging(\"DISABLED\")\n",
    "\n",
    "print(\"\\n‚úÖ Fusion components and Component Activity Monitor initialized!\")\n",
    "print(\"üìä Monitor will display component activities in organized table format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Understanding Prompt Caching: Payload Comparison & Token Savings\n",
    "\n",
    "**üéØ Purpose**: Understand how dual cache breakpoints optimize costs through payload structure and token savings.\n",
    "\n",
    "**Key Concept**: Dual Cache Breakpoint Strategy\n",
    "- **Breakpoint #1**: System prompt (static, always cached after first call)\n",
    "- **Breakpoint #2**: Growing conversation (incremental caching)\n",
    "\n",
    "### üì§ Payload Structure Comparison\n",
    "\n",
    "**Color Legend:**\n",
    "- üü° **Token counts** - Yellow highlighting\n",
    "- üü¢ **CACHED content** - Green highlighting  \n",
    "- üî¥ **BREAKPOINT markers** - Red highlighting\n",
    "- üîµ **NEW BREAKPOINT** - Blue highlighting\n",
    "\n",
    "<div style='display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; margin: 20px 0;'>\n",
    "\n",
    "<div>\n",
    "<h4 style='color: #ff9800; margin-bottom: 10px;'>üî• Call #1 (Cold Start)</h4>\n",
    "<div style='border: 2px solid #ff9800; border-radius: 8px; padding: 15px;'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"system\": [{\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"You are an expert in video analysis...\", // üü° ~1,200 tokens\n",
    "    \"cache_control\": { \"type\": \"ephemeral\" } // üî¥ ‚ö° BREAKPOINT #1\n",
    "  }],\n",
    "  \"messages\": [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\n",
    "      \"type\": \"text\",\n",
    "      \"text\": \"Chunk 0 (0s-20s) Transcript information with precise timestamp...\", // üü° ~1,600 tokens\n",
    "      \"cache_control\": { \"type\": \"ephemeral\" } // üî¥ ‚ö° BREAKPOINT #2\n",
    "    }, {\n",
    "      \"type\": \"image\",\n",
    "      \"source\": {\"data\": \"base64...\"} // üü° ~1,000 tokens\n",
    "    }]\n",
    "  }]\n",
    "}\n",
    "```\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<h4 style='color: #2196f3; margin-bottom: 10px;'>‚ö° Call #2 (Payload)</h4>\n",
    "<div style='border: 2px solid #2196f3; border-radius: 8px; padding: 15px;'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"system\": [{\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"You are an expert in video analysis...\" // üü° ~1,200 tokens üü¢ CACHED ‚ö°\n",
    "  }],\n",
    "  \"messages\": [\n",
    "    // Previous conversation üü¢ CACHED ‚ö°\n",
    "    {\"role\": \"user\", \"content\": \"Chunk 0 (0s-20s) Transcript.....\"}, // üü° ~1,600 tokens üü¢ CACHED ‚ö°\n",
    "    {\"role\": \"assistant\", \"content\": \"Fused understanding response from model...\"}, //  üü° 200 tokens üü¢ CACHED ‚ö°\n",
    "\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"Chunk 1 (20s-40s) Transcript information with precise timestamp...\",\n",
    "        \"cache_control\": { \"type\": \"ephemeral\" } // üîµ ‚ö° NEW BREAKPOINT [ Moved to Call 2 User Input ]\n",
    "      }, {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": {\"data\": \"base64...\"} // üü° ~1,000 tokens\n",
    "      }]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<h4 style='color: #4caf50; margin-bottom: 10px;'>üöÄ Call #3 (Payload)</h4>\n",
    "<div style='border: 2px solid #4caf50; border-radius: 8px; padding: 15px;'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"system\": [{\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"You are an expert in video analysis...\"   // üü¢ CACHED ‚ö°\n",
    "  }],\n",
    "  \"messages\": [\n",
    "    // Extended history üü¢ ALL CACHED ‚ö°\n",
    "    {\"role\": \"user\", \"content\": \"Chunk 0...\"}, // üü° ~1,200 tokens üü¢ CACHED ‚ö°\n",
    "    {\"role\": \"assistant\", \"content\": \"...\"}, // üü° ~1,600 tokens üü¢ CACHED ‚ö°\n",
    "    {\"role\": \"user\", \"content\": \"Chunk 1...\"}, // üü° ~200 tokens üü¢ CACHED ‚ö°\n",
    "    {\"role\": \"assistant\", \"content\": \"...\"}, // üü° ~1,600 tokens üü¢ CACHED ‚ö°\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"Chunk 2 (40s-60s)...\",\n",
    "        \"cache_control\": { \"type\": \"ephemeral\" } // üîµ ‚ö° NEW BREAKPOINT [ Moved to Call 3 User Input and so on.. ]\n",
    "      }, {\n",
    "        \"type\": \"image\",\n",
    "        \"source\": {\"data\": \"base64...\"} // üü° ~1,000 tokens\n",
    "      }]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "### üîç Token Breakdown by Call with Caching\n",
    "\n",
    "<div style='display: flex; gap: 20px; margin: 20px 0; overflow-x: auto;'>\n",
    "\n",
    "<div style='background-color: #fff3e0; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0;'>\n",
    "<h4 style='color: #ff9800; margin-top: 0;'>üî• Call #1 Tokens</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>System Prompt:</strong> ~1,200 tokens</li>\n",
    "<li><strong>Chunk 0 Text:</strong> ~1,600 tokens</li>\n",
    "<li><strong>Image:</strong> ~1,000 tokens</li>\n",
    "<li><strong>Total Input:</strong> 3,800 tokens</li>\n",
    "<li><strong>Cache Write:</strong> 2,800 tokens</li>\n",
    "<li><strong>Cache Read:</strong> 0 tokens</li>\n",
    "<li><strong>Hit Ratio:</strong> 0%</li>\n",
    "<li><strong>Token Savings:</strong> 0%</li>\n",
    "<li><strong>Duration:</strong> 3.2s</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #e3f2fd; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0;'>\n",
    "<h4 style='color: #2196f3; margin-top: 0;'>‚ö° Call #2 Tokens</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>System Prompt:</strong> CACHED ‚ö°</li>\n",
    "<li><strong>Old Conversations:</strong> CACHED ‚ö°</li>\n",
    "<li><strong>Chunk 1 Text:</strong> ~1,600 tokens</li>\n",
    "<li><strong>Image:</strong> ~1,000 tokens</li>\n",
    "<li><strong>Total Input:</strong> 6,800 tokens</li>\n",
    "<li><strong>Cache Write:</strong> 2,600 tokens</li>\n",
    "<li><strong>Cache Read:</strong> 4,200 tokens</li>\n",
    "<li><strong>Hit Ratio:</strong> 62%</li>\n",
    "<li><strong>Token Savings:</strong> 56%</li>\n",
    "<li><strong>Duration:</strong> 2.8s</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #e8f5e9; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0;'>\n",
    "<h4 style='color: #4caf50; margin-top: 0;'>üöÄ Call #3 Tokens</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>System Prompt:</strong> CACHED ‚ö°</li>\n",
    "<li><strong>Old Coversations:</strong> CACHED ‚ö°</li>\n",
    "<li><strong>Chunk 2 Text:</strong> ~1,600 tokens</li>\n",
    "<li><strong>Image:</strong> ~1,000 tokens</li>\n",
    "<li><strong>Total Input:</strong> 9,400 tokens</li>\n",
    "<li><strong>Cache Write:</strong> 2,600 tokens</li>\n",
    "<li><strong>Cache Read:</strong> 6,800 tokens</li>\n",
    "<li><strong>Hit Ratio:</strong> 72%</li>\n",
    "<li><strong>Token Savings:</strong> 65%</li>\n",
    "<li><strong>Duration:</strong> 2.5s</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "### üìä Token Breakdown by Call without Caching\n",
    "\n",
    "<div style='display: flex; gap: 20px; margin: 20px 0; overflow-x: auto;'>\n",
    "\n",
    "<div style='background-color: #ffebee; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #f44336;'>\n",
    "<h4 style='color: #d32f2f; margin-top: 0;'>üî• Call #1 (No Cache)</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>System Prompt:</strong> ~1,200 tokens</li>\n",
    "<li><strong>Chunk 0 Text:</strong> ~1,600 tokens</li>\n",
    "<li><strong>Image:</strong> ~1,000 tokens</li>\n",
    "<li><strong>Total Input:</strong> 3,800 tokens</li>\n",
    "<li><strong>Cache Write:</strong> 0 tokens</li>\n",
    "<li><strong>Cache Read:</strong> 0 tokens</li>\n",
    "<li><strong>Hit Ratio:</strong> 0%</li>\n",
    "<li><strong>Token Savings:</strong> 0%</li>\n",
    "<li><strong>Duration:</strong> 3.2s</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #ffebee; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #f44336;'>\n",
    "<h4 style='color: #d32f2f; margin-top: 0;'>üî• Call #2 (No Cache)</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>System Prompt:</strong> ~1,200 tokens</li>\n",
    "<li><strong>Previous Conv:</strong> ~1,800 tokens</li>\n",
    "<li><strong>Chunk 1 Text:</strong> ~1,600 tokens</li>\n",
    "<li><strong>Image:</strong> ~1,000 tokens</li>\n",
    "<li><strong>Total Input:</strong> 5,600 tokens</li>\n",
    "<li><strong>Cache Write:</strong> 0 tokens</li>\n",
    "<li><strong>Cache Read:</strong> 0 tokens</li>\n",
    "<li><strong>Hit Ratio:</strong> 0%</li>\n",
    "<li><strong>Token Savings:</strong> 0%</li>\n",
    "<li><strong>Duration:</strong> 4.1s</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #ffebee; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #f44336;'>\n",
    "<h4 style='color: #d32f2f; margin-top: 0;'>üî• Call #3 (No Cache)</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>System Prompt:</strong> ~1,200 tokens</li>\n",
    "<li><strong>Full History:</strong> ~3,400 tokens</li>\n",
    "<li><strong>Chunk 2 Text:</strong> ~1,600 tokens</li>\n",
    "<li><strong>Image:</strong> ~1,000 tokens</li>\n",
    "<li><strong>Total Input:</strong> 7,200 tokens</li>\n",
    "<li><strong>Cache Write:</strong> 0 tokens</li>\n",
    "<li><strong>Cache Read:</strong> 0 tokens</li>\n",
    "<li><strong>Hit Ratio:</strong> 0%</li>\n",
    "<li><strong>Token Savings:</strong> 0%</li>\n",
    "<li><strong>Duration:</strong> 4.8s</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "### üí° Caching vs No Caching Comparison\n",
    "\n",
    "| Metric | Call #1 | Call #2 | Call #3 | Total |\n",
    "|--------|---------|---------|---------|-------|\n",
    "| **With Caching (Input)** | 3,800 tokens | 2,600 tokens | 2,600 tokens | **9,000 tokens** |\n",
    "| **Without Caching (Input)** | 3,800 tokens | 5,600 tokens | 7,200 tokens | **16,600 tokens** |\n",
    "| **Cache Efficiency** | Same | 54% fewer tokens | 64% fewer tokens | **46% total savings** |\n",
    "| **Duration Savings** | Same | 32% faster | 48% faster | **Average 27% faster** |\n",
    "\n",
    "**Key Insights:**\n",
    "- üéØ **Caching dramatically reduces input tokens** (2,600 vs 5,600 in Call #2)\n",
    "- üìà **Benefits compound with each call** (54% ‚Üí 64% token reduction)\n",
    "- ‚ö° **Significant latency improvements** (up to 48% faster)\n",
    "- üí∞ **46% total token savings** across all calls with caching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Smart Context Windowing: Chapter Management & Token Optimization\n",
    "\n",
    "**üéØ Purpose**: Optimize token usage by intelligently managing finalized chapters in the context window while maintaining analysis accuracy.\n",
    "\n",
    "**Key Concept**: Chapter-Based Rolling Window Strategy\n",
    "- **Continuous Processing**: Each 20-second chunk is analyzed and mapped to chapters\n",
    "- **Chapter Finalization**: When chapters are completed, windowing is triggered\n",
    "- **Intelligent Retention**: Keep only configured number of finalized chapters (n=1 recommended)\n",
    "- **Context Cleanup**: Remove old chapters to prevent context overflow\n",
    "\n",
    "### üìä Chapter Context Comparison\n",
    "\n",
    "**Processing Flow with Chunk-Chapter Mapping:**\n",
    "```\n",
    "Chunk 0 ‚Üí Chapter 1 (incomplete) [Chunks: 0]\n",
    "Chunk 1 ‚Üí Chapter 1 (finalized) [Chunks: 0,1] + Chapter 2 (incomplete) [Chunks: 1]\n",
    "Chunk 2 ‚Üí Chapter 2 (finalized) [Chunks: 1,2] + Chapter 3 (incomplete) [Chunks: 2]\n",
    "Chunk 3 ‚Üí Chapter 3 (finalized) [Chunks: 2,3] + Chapter 4 (incomplete) [Chunks: 3]\n",
    "\n",
    "Windowing Logic:\n",
    "- When Chapter 1 is either being generated or finalized: No windowing needed as there are no prior chapters available.\n",
    "\n",
    "- When Chapter 2 is being generated: Keep Chapter 1 (last finalized) chunks + Chapter 2 (current) chunks\n",
    "- When Chapter 2 is finalized:\n",
    "    - Find all the non-overlapping chunks in Chapter 1: Chunk 0 (not in Chapter 2)\n",
    "    - Delete Chunk 0 messages from context\n",
    "\n",
    "- When Chapter 3 is being generated: Keep Chapter 2 (last finalized) chunks + Chapter 3 (current) chunks\n",
    "- When Chapter 3 is finalized:\n",
    "    - Find all the non-overlapping chunks in Chapter 2: Chunk 1 (not in Chapter 2,3)\n",
    "    - Delete Chunk 1 messages from context\n",
    "```\n",
    "\n",
    "### üîç Chapter Context with Rolling (keep_n_chapters = 1)\n",
    "\n",
    "<div style='display: flex; gap: 20px; margin: 20px 0; overflow-x: auto;'>\n",
    "\n",
    "<div style='background-color: #e8f5e9; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #4caf50;'>\n",
    "<h4 style='color: #2e7d32; margin-top: 0;'>üìù After Chunk 0</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>Chapter 1:</strong> Incomplete [Chunk 0]</li>\n",
    "<li><strong>Chapters in Context:</strong> 1</li>\n",
    "<li><strong>Context Messages:</strong> 2</li>\n",
    "<li><strong>Context Tokens:</strong> ~1,200</li>\n",
    "<li><strong>Windowing Action:</strong> None (no finalized chapters)</li>\n",
    "<li><strong>Memory Status:</strong> Growing</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #e8f5e9; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #4caf50;'>\n",
    "<h4 style='color: #2e7d32; margin-top: 0;'>üìù After Chunk 1</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>Chapter 1:</strong> ‚úÖ Finalized [Chunks 0,1]</li>\n",
    "<li><strong>Chapter 2:</strong> Incomplete [Chunk 1]</li>\n",
    "<li><strong>Chapters in Context:</strong> 2</li>\n",
    "<li><strong>Context Messages:</strong> 4</li>\n",
    "<li><strong>Context Tokens:</strong> ~3,800</li>\n",
    "<li><strong>Windowing Action:</strong> Keep Chapter 1 (within limit)</li>\n",
    "<li><strong>Memory Status:</strong> Controlled</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #e8f5e9; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #4caf50;'>\n",
    "<h4 style='color: #2e7d32; margin-top: 0;'>üìù After Chunk 2</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>Chapter 1:</strong> üóëÔ∏è Remove non-overlapping Chunk 0</li>\n",
    "<li><strong>Chapter 2:</strong> ‚úÖ Finalized [Chunks 1,2] (kept)</li>\n",
    "<li><strong>Chapter 3:</strong> Incomplete [Chunk 2]</li>\n",
    "<li><strong>Chapters in Context:</strong> 2</li>\n",
    "<li><strong>Context Messages:</strong> 4 ‚ö° Cleanup</li>\n",
    "<li><strong>Context Tokens:</strong> ~3,200</li>\n",
    "<li><strong>Windowing Action:</strong> Deleted Chunk 0 (non-overlapping)</li>\n",
    "<li><strong>Memory Status:</strong> Bounded</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "### üìà Chapter Context without Rolling (keep_n_chapters = None)\n",
    "\n",
    "<div style='display: flex; gap: 20px; margin: 20px 0; overflow-x: auto;'>\n",
    "\n",
    "<div style='background-color: #ffebee; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #f44336;'>\n",
    "<h4 style='color: #d32f2f; margin-top: 0;'>üìù After Chunk 0</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>Chapters in Context:</strong> 1</li>\n",
    "<li><strong>Chapter 1:</strong> Incomplete (Chunk 0)</li>\n",
    "<li><strong>Context Messages:</strong> 2</li>\n",
    "<li><strong>Context Tokens:</strong> ~1,200</li>\n",
    "<li><strong>Windowing Action:</strong> None</li>\n",
    "<li><strong>Memory Status:</strong> Growing</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #ffebee; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #f44336;'>\n",
    "<h4 style='color: #d32f2f; margin-top: 0;'>üìù After Chunk 1</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>Chapters in Context:</strong> 2</li>\n",
    "<li><strong>Chapter 1:</strong> ‚úÖ Finalized (kept)</li>\n",
    "<li><strong>Chapter 2:</strong> Incomplete (Chunk 1)</li>\n",
    "<li><strong>Context Messages:</strong> 4</li>\n",
    "<li><strong>Context Tokens:</strong> ~3,800</li>\n",
    "<li><strong>Windowing Action:</strong> None (keep all)</li>\n",
    "<li><strong>Memory Status:</strong> Growing</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style='background-color: #ffebee; border-radius: 8px; padding: 15px; min-width: 300px; flex-shrink: 0; border: 2px solid #f44336;'>\n",
    "<h4 style='color: #d32f2f; margin-top: 0;'>üìù After Chunk 2</h4>\n",
    "<ul style='margin: 0; padding-left: 20px;'>\n",
    "<li><strong>Chapters in Context:</strong> 3</li>\n",
    "<li><strong>Chapter 1:</strong> ‚úÖ Finalized (kept)</li>\n",
    "<li><strong>Chapter 2:</strong> ‚úÖ Finalized (kept)</li>\n",
    "<li><strong>Chapter 3:</strong> Incomplete (Chunk 2)</li>\n",
    "<li><strong>Context Messages:</strong> 6</li>\n",
    "<li><strong>Context Tokens:</strong> ~6,400</li>\n",
    "<li><strong>Windowing Action:</strong> None (unbounded growth)</li>\n",
    "<li><strong>Memory Status:</strong> Unbounded</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "### üí° Rolling vs No Rolling Comparison\n",
    "\n",
    "| Metric | After Chunk 0 | After Chunk 1 | After Chunk 2 | Total Growth |\n",
    "|--------|---------------|---------------|---------------|---------------|\n",
    "| **With Rolling (Messages)** | 2 | 4 | 4 ‚ö° | **Bounded (4 max)** |\n",
    "| **Without Rolling (Messages)** | 2 | 4 | 6 | **Unbounded (grows linearly)** |\n",
    "| **With Rolling (Tokens)** | 1,200 | 3,800 | 3,200 ‚ö° | **28% token reduction** |\n",
    "| **Without Rolling (Tokens)** | 1,200 | 3,800 | 6,400 | **Unlimited growth** |\n",
    "| **Memory Efficiency** | Same | Same | 50% fewer tokens | **Scalable to unlimited length** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize Processing Components\n",
    "\n",
    "**Set up the core processors** for multi-modal fusion pipeline.\n",
    "\n",
    "### Processing Components\n",
    "\n",
    "- **RecordingManager** - captures video stream to MXF format for archival\n",
    "- **ChunkProcessor** - creates video chunks and filmstrips with shot detection\n",
    "- **TranscriptionProcessor** - real-time audio transcription with memory integration\n",
    "- **FusionAnalyzer** - multi-modal analysis using Claude with memory storage\n",
    "\n",
    "Each processor is optimized for real-time processing and cost efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize all processors\n",
    "recording_manager = RecordingManager(UDP_PORT_RECORDING, OUTPUT_DIR)\n",
    "transcription_processor = TranscriptionProcessor(UDP_PORT_TRANSCRIPTION, AWS_REGION, SENTENCE_JSON_BUFFER, memory_client=memory_client, memory_id=transcript_mem_id, actor_id=actor_id, session_id=trans_session_id, output_dir=OUTPUT_DIR)\n",
    "fusion_analyzer = FusionAnalyzer(AWS_REGION, SENTENCE_JSON_BUFFER, CHUNK_ANALYSIS_RESULTS, OUTPUT_DIR, memory_client=memory_client, memory_id=video_analysis_mem_id, actor_id=actor_id, session_id=video_analysis_session_id)\n",
    "\n",
    "# Initialize chunk processor (FFmpeg only - no monitoring)\n",
    "chunk_processor = ChunkProcessor(UDP_PORT_PROCESSING, OUTPUT_DIR, CHUNK_DURATION)\n",
    "\n",
    "# Initialize chunk monitor (separate process for monitoring and processing chunks)\n",
    "chunk_monitor = ChunkMonitor(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    chunk_duration=CHUNK_DURATION,\n",
    "    fusion_analyzer=fusion_analyzer,\n",
    "    check_interval=0.5  # Check for new chunks every 0.5 seconds\n",
    ")\n",
    "\n",
    "# Initialize chapters table\n",
    "fusion_analyzer.initialize_display()\n",
    "\n",
    "print(\"‚úÖ All processors initialized with fusion integration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Start Multi-modal Fusion Processing\n",
    "\n",
    "**Execute the complete multi-modal fusion pipeline** with real-time processing and analysis.\n",
    "\n",
    "**What Happens:**\n",
    "1. **Component Monitor**: Displays organized activity log for all processors\n",
    "2. **Parallel Processing**: Starts recording, chunk processing, and transcription simultaneously\n",
    "3. **Multi-modal Fusion**: Analyzes visual filmstrips + audio transcripts every 20 seconds\n",
    "4. **Chapter Detection**: Identifies topic boundaries and creates chapters\n",
    "5. **Real-time Display**: Updates chapter table every 3 seconds\n",
    "6. **AgentCore Memory**: Pushes fused understanding to memory in real-time\n",
    "7. **Cost Optimization**: Uses prompt caching to reduce token costs\n",
    "\n",
    "**üìù System Prompt**: The multi-modal analysis is powered by a comprehensive system prompt that guides Claude's understanding of video content. You can review the complete prompt at: [`prompts/video_analysis_system_prompt.txt`](prompts/video_analysis_system_prompt.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Source Video With FFmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Change to sample_videos directory\n",
    "video_dir = \"../sample_videos\"\n",
    "video_file = \"Netflix_Open_Content_Meridian.mp4\"\n",
    "video_path = os.path.join(video_dir, video_file)\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    print(f\"üé¨ Starting FFmpeg stream from: {video_path}\")\n",
    "    print(\"‚è≥ Waiting 5 seconds before starting stream...\")\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # FFmpeg command for multi-stream output\n",
    "    ffmpeg_cmd = [\n",
    "        \"ffmpeg\", \"-re\", \"-i\", video_path,\n",
    "        \"-c:v\", \"copy\", \"-c:a\", \"copy\", \"-f\", \"tee\", \n",
    "        \"-map\", \"0:v\", \"-map\", \"0:a\",\n",
    "        \"[f=mpegts]udp://127.0.0.1:1234|[f=mpegts]udp://127.0.0.1:1235|[f=mpegts]udp://127.0.0.1:1236\"\n",
    "    ]\n",
    "    \n",
    "    def run_ffmpeg():\n",
    "        try:\n",
    "            # Redirect stdout and stderr to DEVNULL to suppress FFmpeg logs\n",
    "            subprocess.run(\n",
    "                ffmpeg_cmd, \n",
    "                check=True,\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL\n",
    "            )\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå FFmpeg error: {e}\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"üõë FFmpeg stopped by user\")\n",
    "    \n",
    "    # Start FFmpeg in background thread\n",
    "    ffmpeg_thread = threading.Thread(target=run_ffmpeg, daemon=True)\n",
    "    ffmpeg_thread.start()\n",
    "    print(\"‚úÖ FFmpeg started in background thread\")\n",
    "    print(\"üì∫ Stream should now be available on UDP ports 1234, 1235, 1236\")\n",
    "else:\n",
    "    print(f\"‚ùå Video file not found: {video_path}\")\n",
    "    print(\"Please ensure the sample video is in the correct location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #ffebee; border: 3px solid #c62828; border-radius: 5px; padding: 15px; margin: 10px 0;'>\n",
    "<h3 style='color: #c62828; margin-top: 0;'>‚ö†Ô∏è IMPORTANT: Before executing the next cell...</h3>\n",
    "<p style='margin: 10px 0;'><strong>Duration:</strong> In the below cell, the processing duration is set to <b>5 minutes</b> by default through the <code>duration_minutes</code> parameter.</p>\n",
    "<p style='margin: 10px 0; color: #2e7d32; font-weight: bold;'>üì∫ The source video will be processed in real-time and you will see chapters and topics appearing within the chapters table as the live content is ingested and analyzed.</p>\n",
    "<p style='margin: 10px 0; color: #f57c00; font-weight: bold;'>‚è≥ Note: The chapters table will continuously refresh during processing. Please wait for the processing to fully complete and allow some time for the table to settle down before interacting with it to analyze the final output.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up chapter table display\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from ipywidgets import Output\n",
    "\n",
    "# Create separate output widgets for logs and chapter table\n",
    "chapter_table_output = Output()\n",
    "logs_output = Output()\n",
    "\n",
    "# Display chapter table widget first (refreshable)\n",
    "display(chapter_table_output)\n",
    "\n",
    "# Display logs widget second (persistent)\n",
    "display(logs_output)\n",
    "\n",
    "# Redirect component monitor logs to the logs widget\n",
    "with logs_output:\n",
    "    component_monitor.show_table()\n",
    "\n",
    "def refresh_chapter_table():\n",
    "    \"\"\"Refresh only the chapter table, not the logs\"\"\"\n",
    "    try:\n",
    "        with chapter_table_output:\n",
    "            clear_output(wait=True)\n",
    "            html = fusion_analyzer.get_chapter_table_html()\n",
    "            display(HTML(html))\n",
    "    except Exception as e:\n",
    "        pass  # Silently handle any display errors\n",
    "\n",
    "# Execute the fusion processing using utility function\n",
    "await start_fusion_processing(\n",
    "    duration_minutes=5,\n",
    "    recording_manager=recording_manager,\n",
    "    chunk_processor=chunk_processor,\n",
    "    chunk_monitor=chunk_monitor,\n",
    "    fusion_analyzer=fusion_analyzer,\n",
    "    transcription_processor=transcription_processor,\n",
    "    stream_monitor_class=StreamMonitor,\n",
    "    log_component=log_component,\n",
    "    refresh_chapter_table=refresh_chapter_table\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup - Stop FFmpeg Processes\n",
    "\n",
    "**Clean up FFmpeg processes** to prevent conflicts with other modules and free system resources.\n",
    "\n",
    "<div style='background-color: #fff3e0; border: 2px solid #f57c00; border-radius: 5px; padding: 15px; margin: 10px 0;'>\n",
    "<h3 style='color: #f57c00; margin-top: 0;'>üßπ Cleanup Recommendation</h3>\n",
    "<p style='margin: 10px 0;'><strong>Run this cell after processing is complete to ensure clean shutdown.</strong></p>\n",
    "<p style='margin: 10px 0;'>This will:</p>\n",
    "<ul style='margin: 5px 0;'>\n",
    "<li>Kill any running FFmpeg processes</li>\n",
    "<li>Free up UDP ports (1234, 1235, 1236)</li>\n",
    "<li>Prevent conflicts with other notebook modules</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set to False to skip this cleanup step\n",
    "SKIP_CLEANUP = False\n",
    "\n",
    "# Use cleanup utility function\n",
    "cleanup_ffmpeg_processes(skip_cleanup=SKIP_CLEANUP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
